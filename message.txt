import torch
from torch import nn
import cv2
import numpy as np
import os
import torchvision.transforms.functional as TF
import torch.optim as optim
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import random
import glob
import matplotlib.pyplot as plt

NUM_EPOCHS = 200
LEARNING_RATE = 0.5
BATCH_SIZE = 32
NOISE_FACTOR = 0.5
s=256

class MyDataset(torch.utils.data.Dataset):
    def __init__(self, image_paths):
        self.image_paths = image_paths

    def __getitem__(self, index):
        path = self.image_paths[index]
        gt = cv2.imread(path.replace('.npy', '.png'),0)
        path_transformed = os.path.join(os.path.dirname(os.path.dirname(path)),"images", os.path.basename(path).replace(".png",".npy"))
        image_transformed = np.array(np.load(path_transformed), dtype=np.float32)
        gt = cv2.resize(gt,dsize=(s,s)).astype(np.float32)
        image_transformed = cv2.resize(image_transformed,dsize=(s,s)).astype(np.float32)
        gt /= np.max(gt)
        image_transformed /= np.max(image_transformed)
        gt = np.fft.fftshift(np.fft.fft2(gt), axes=(0, 1))
        image_transformed = np.fft.fftshift(np.fft.fft2(image_transformed), axes=(0, 1))
        # transformations, e.g. Random Crop etc.
        # Make sure to perform the same transformations on image and target
        # Here is a small example: https://discuss.pytorch.org/t/torchvision-transfors-how-to-perform-identical-transform-on-both-image-and-target/10606/7?u=ptrblck
        #image_transformed = cv2.GaussianBlur(gt,(9,9),0)
        x, y = TF.to_tensor(gt), TF.to_tensor(image_transformed)
        return x, y

    def __len__(self):
        return len(self.image_paths)

class TrainableEltwiseLayer(nn.Module):
  def __init__(self, n, h, w):
    super(TrainableEltwiseLayer, self).__init__()
    self.weights = nn.Parameter(torch.Tensor(1, n, h, w).type(torch.complex128))  # define the trainable parameter

  def forward(self, x):
    # assuming x is of size b-1-h-w
    return x @ self.weights # element-wise multiplication



transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,)),
])

if __name__ == '__main__':
    criterion = nn.MSELoss()
    # criterion = nn.L1Loss()
    # the optimizer
    model = TrainableEltwiseLayer(n=1, h=256, w=256)  # instantiate a model
    for m in model.modules():
        if isinstance(m, nn.Conv2d):
            nn.init.normal_(m.weights.data)  # init for conv layers
        if isinstance(m, TrainableEltwiseLayer):
            nn.init.constant_(m.weights.data, 1)  # init for eltwise layers
            # nn.init.normal_(m.weights.data, mean=1, std=0.1)  # init for eltwise layers

    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

    decayRate = 0.96
    my_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)

    dir_path = r"data/gt"
    paths = glob.glob(os.path.join(dir_path, "*.npy"))

    dataset = MyDataset(paths)
    train_set, test_set = torch.utils.data.random_split(dataset, [800, 100])
    trainloader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)
    testloader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)
    train_loss = []
    for epoch in range(NUM_EPOCHS):
        running_loss = 0.0
        for data in trainloader:
            model.train()
            img, img_noisy = data

            optimizer.zero_grad()
            outputs = model(img_noisy)
            loss = criterion(torch.real(outputs), torch.real(img))
            # backpropagation
            loss.backward()
            # update the parameters
            optimizer.step()
            running_loss += loss.item()

        loss = running_loss / len(trainloader)
        train_loss.append(loss)
        print('Epoch {} of {}, Train Loss: {:.6f}'.format(
            epoch + 1, NUM_EPOCHS, loss))

        my_lr_scheduler.step()

        if epoch % 10 == 0:
            plt.subplot(1, 3, 1)
            plt.imshow(np.abs(np.fft.ifft2(np.fft.ifftshift(img[0,0,:,:].detach().numpy()))), cmap='hot')
            plt.title("GT")
            plt.axis('off')
            plt.subplot(1, 3, 2)
            plt.imshow(np.abs(np.fft.ifft2(np.fft.ifftshift(img_noisy[0,0,:,:].detach().numpy()))), cmap='hot')
            plt.title("Input")
            plt.axis('off')
            plt.subplot(1, 3, 3)
            plt.imshow(np.abs(np.fft.ifft2(np.fft.ifftshift(outputs[0,0,:,:].detach().numpy()))), cmap='hot')
            plt.title("Output")
            plt.axis('off')
            plt.show()

            test_loss = 0.0
            for data in testloader:
                model.eval()
                img, img_noisy = data
                outputs = model(img_noisy)
                loss = criterion(torch.real(outputs), torch.real(img))
                test_loss += loss.item()
            print('-' * 50)
            print('Epoch {} of {}, Test Loss: {:.6f}'.format(
                epoch + 1, NUM_EPOCHS, test_loss / len(testloader)))
            print('-' * 50)

            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'loss': loss
            }, f'./weights/e{epoch}.pth')


