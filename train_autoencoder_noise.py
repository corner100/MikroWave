# -*- coding: utf-8 -*-
"""Denoising Autoencoder FashionMNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    <https://colab.research.google.com/drive/1BAv35ZLBHwqbqitX802mfGDxEdM2j911>
"""


# imports
import os
import torch
import torchvision
import numpy as np
import torch.nn as nn
import torchvision.transforms as transforms
import torch.optim as optim
import matplotlib.pyplot as plt
import torch.nn.functional as F
from torchvision import datasets
from torch.utils.data import DataLoader
from torchvision.utils import save_image
import matplotlib.pyplot as plt
import cv2
import glob
import torchvision.transforms.functional as TF
from torchsummary import summary
import my_model_zoo

# constants
NUM_EPOCHS = 100
LEARNING_RATE = 0.0005
BATCH_SIZE = 32
NOISE_FACTOR = 0.5
s=256
# transforms
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,)),
])

class MyDataset(torch.utils.data.Dataset):
    def __init__(self, image_paths):
        self.image_paths = image_paths

    def __getitem__(self, index):
        path = self.image_paths[index]
        gt = cv2.imread(path,0)
        path_transformed = os.path.join(os.path.dirname(os.path.dirname(path)),"images", os.path.basename(path).replace(".png",".npy"))
        image_transformed = np.array(np.load(path_transformed), dtype=np.float32)
        gt = cv2.resize(gt,dsize=(s,s))
        image_transformed = cv2.resize(image_transformed,dsize=(s,s))
        # transformations, e.g. Random Crop etc.
        # Make sure to perform the same transformations on image and target
        # Here is a small example: https://discuss.pytorch.org/t/torchvision-transfors-how-to-perform-identical-transform-on-both-image-and-target/10606/7?u=ptrblck
        #image_transformed = cv2.GaussianBlur(gt,(9,9),0)
        x, y = TF.to_tensor(gt), TF.to_tensor(image_transformed)
        return x, y

    def __len__(self):
        return len(self.image_paths)

dir_path = r"data/gt"
paths = glob.glob(os.path.join(dir_path,"*"))
import random
random.shuffle(paths)
#trainset = datasets.FashionMNIST(root='~/torch_datasets', train=True, download=True, transform=transform)
trainset = MyDataset(paths)
#testset = datasets.FashionMNIST(root='~/torch_datasets', train=False, download=True, transform=transform)
testset = MyDataset(paths)
trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)
testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=True)


def get_device():
    if torch.cuda.is_available():
        device = 'cuda:0'
    else:
        device = 'cpu'
    return device


def make_dir():
    image_dir = 'Saved_Images'
    if not os.path.exists(image_dir):
        os.makedirs(image_dir)


def save_decoded_image(img, name):
    img = img.view(img.size(0), 1, s, s)
    save_image(img, name)


#net = my_model_zoo.Autoencoder()
net = my_model_zoo.UNet(enc_chs=(1, 64, 128, 256, 512,1024), dec_chs=(1024, 512, 256, 128, 64), num_class=1,
                 retain_dim=True, out_sz=(256, 256))
print(net)
#summary(net,input_size=(1, 612, 612))
criterion = nn.MSELoss()
# the optimizer
optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)


def train(net, trainloader, NUM_EPOCHS):
    train_loss = []
    for epoch in range(NUM_EPOCHS):
        running_loss = 0.0
        for data in trainloader:
            img, img_noisy = data
            img, img_noisy = img.cuda(), img_noisy.cuda()

            optimizer.zero_grad()
            outputs = net(img_noisy)
            loss = criterion(outputs, img)
            # backpropagation
            loss.backward()
            # update the parameters
            optimizer.step()
            running_loss += loss.item()

        loss = running_loss / len(trainloader)
        train_loss.append(loss)
        print('Epoch {} of {}, Train Loss: {:.3f}'.format(
            epoch + 1, NUM_EPOCHS, loss))
        if epoch % 1 == 0:
            save_decoded_image(img_noisy.cpu().data, name='./Saved_Images/noisy{}.png'.format(epoch))
            save_decoded_image(outputs.cpu().data, name='./Saved_Images/denoised{}.png'.format(epoch))

    return train_loss


def test_image_reconstruction(net, testloader):
    for batch in testloader:
        img, _ = batch
        img_noisy = img + NOISE_FACTOR * torch.randn(img.shape)
        img_noisy = np.clip(img_noisy, 0., 1.)
        img_noisy = img_noisy.to(device)
        outputs = net(img_noisy)
        outputs = outputs.view(outputs.size(0), 1, s, s).cpu().data
        save_image(img_noisy, 'noisy_test_input.png')
        save_image(outputs, 'denoised_test_reconstruction.png')
        break


device = get_device()
print(device)
net.to(device)
make_dir()
train_loss = train(net, trainloader, NUM_EPOCHS)
plt.figure()
plt.plot(train_loss)
plt.title('Train Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.savefig('./Saved_Images/conv_ae_fahsionmnist_loss.png')
test_image_reconstruction(net, testloader)

